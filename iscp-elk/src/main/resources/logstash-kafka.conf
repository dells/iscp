# Sample Logstash configuration for creating a simple
# logback -> kafka -> Logstash -> Elasticsearch pipeline.

input {
     kafka {
        #Value type is string
        #There is no default value for this setting.
        #A topic regex pattern to subscribe to.The topics configuration will be ignored when using this configuration.
        topics => ["all_logs"]
        #Value type isstring
        #Default value is "localhost:9092"
        #A list of URLs of Kafka instances to use for establishing the initial connection to the cluster. This list should be in the form of host1:port1,host2:port2 These urls are just used for the initial connection to discover the full cluster membership (which may change dynamically) so this list need not contain the full set of servers (you may want more than one, though, in case a server is down).
        bootstrap_servers => "localhost:9092"
        #Value type is codec
        #Default value is "plain"
        #The codec used for input data. Input codecs are a convenient method for decoding your data before it enters the input, without needing a separate filter in your Logstash pipeline.
        #codec => "json"
		codec=>plain{
			charset=>"UTF-8"
		}
    }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "kafka-%{+YYYY.MM.dd}" #用一个项目名称来做索引
    #user => "elastic"
    #password => "changeme"
  }
  stdout { codec => rubydebug }
}
